{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: dlib-bin in /home/dkong/.local/lib/python3.9/site-packages (19.24.2.post1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "oe = preprocessing.OneHotEncoder(sparse=False)\n",
    "import dlib\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import timeit\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Structured SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows Length\n",
    "L_values= [2, 3, 4, 5]\n",
    "# Splits\n",
    "splits = [(1000, 4000), (2500, 2500), (4000, 1000)]\n",
    "# Number of examples\n",
    "N = 5000\n",
    "# Length of a feature\n",
    "d = 128\n",
    "# The hyper-parameter for icm search\n",
    "Niter = 2               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2i(a):\n",
    "        return int(ord(a)-ord('a'))\n",
    "def i2l(i):\n",
    "    if i >= 0:\n",
    "        return chr(i+ord('a'))\n",
    "    else:\n",
    "        return '_'\n",
    "def iors(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError: # if it is a string, return a string\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the entire dataset into lists or list of lists\n",
    "def read_OCR(filename, n_features):\n",
    "    F = open(filename)\n",
    "    dataset = {}\n",
    "    dataset['ids'] = []#np.zeros(n_examples, dtype=int)\n",
    "    dataset['labels'] = []#np.zeros(n_examples,dtype=int)\n",
    "    dataset['labelDic'] = {} # To profile the distribution of labels\n",
    "    dataset['next_ids'] = []#np.zeros(n_examples,dtype=int)\n",
    "    dataset['word_ids'] = []#np.zeros(n_examples,dtype=int)\n",
    "    dataset['positions'] = []#np.zeros(n_examples,dtype=int)\n",
    "    dataset['folds'] = []#np.zeros(n_examples,dtype=int)\n",
    "    dataset['features'] = []#np.zeros([n_examples,n_features])\n",
    "    \n",
    "    for str_line in F.readlines():\n",
    "        #line0 = map(iors, filter(None, re.split('\\t', str_line.strip())))\n",
    "        ## ATTENTION: If you are using Python3, use the following line instead\n",
    "        line0 = list(map(iors, filter(None, re.split('\\t', str_line.strip()))))\n",
    "\n",
    "\n",
    "        dataset['ids'].append(int(line0.pop(0)))\n",
    "        dataset['labels'].append(l2i(line0.pop(0))) # The label is converted into integer('a'=>0, 'z'=>25)\n",
    "        if dataset['labels'][-1] in dataset['labelDic']:\n",
    "            dataset['labelDic'][dataset['labels'][-1]] += 1\n",
    "        else:\n",
    "            dataset['labelDic'][dataset['labels'][-1]] = 1\n",
    "            \n",
    "        dataset['next_ids'].append(int(line0.pop(0)))\n",
    "        dataset['word_ids'].append(int(line0.pop(0)))\n",
    "        dataset['positions'].append(int(line0.pop(0)))\n",
    "        dataset['folds'].append(int(line0.pop(0)))\n",
    "        if len(line0) != 128:  # Sanity check of the length\n",
    "            print (len(line0))\n",
    "        dataset['features'].append(line0)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = read_OCR('OCRdataset/letter.data', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of labels= 25  min of labels= 0 num of labels= 26\n",
      "labelDic.keys()= <map object at 0x7fe6ef512190>\n",
      "Total number of lines= 52152\n",
      "The shape of features: (52152, 128)\n",
      "The first 10 ids: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "ids[0]= 1\n",
      "labels[0]= 14\n",
      "The 1st letter is  o\n",
      "next_ids[0]= 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Understand the profile of OCR raw data\n",
    "print (\"max of labels=\", max(dataset1['labels']), \" min of labels=\", min(dataset1['labels']), 'num of labels=', len(dataset1['labelDic']))\n",
    "print (\"labelDic.keys()=\", map(i2l, dataset1['labelDic'].keys()))\n",
    "print (\"Total number of lines=\", len(dataset1['ids']))\n",
    "print (\"The shape of features:\", np.array(dataset1['features']).shape)\n",
    "\n",
    "print (\"The first 10 ids:\",dataset1['ids'][:10])\n",
    "print (\"ids[0]=\",dataset1['ids'][0])\n",
    "print (\"labels[0]=\", dataset1['labels'][0])\n",
    "print (\"The 1st letter is \", i2l(dataset1['labels'][0]))\n",
    "print (\"next_ids[0]=\",dataset1['next_ids'][0])\n",
    "# Show the matrix into an image\n",
    "def showFeatures(features, num):\n",
    "    plt.figure(figsize=(num, 6))\n",
    "    \n",
    "    for i in range(num):\n",
    "        npfeature = np.array(features[i])\n",
    "        plt.subplot(1,num,i+1)\n",
    "        imshow(npfeature.reshape(16,8), cmap='gray')\n",
    "        plt.title(i)\n",
    "\n",
    "showFeatures(dataset1['features'],20)\n",
    "\n",
    "# f1 = np.array(dataset1['features'])\n",
    "# f1 = np.hstack([np.ones((f1.shape[0],1)), f1])\n",
    "# print f1.shape\n",
    "# dataset1['features'] = f1.tolist()\n",
    "# d +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options for Chopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating and structurizing\n",
    "### version one:\n",
    "####  (1) find 5000 words, split them into 4000 for training, and 1000 for testing. \n",
    "####  (2) chop first 2 characters from each word\n",
    "####  (3) then, you will have 4000 two-words pairs for training, and 1000 for testing. \n",
    "####  (4) construct new structures data based on this pairs. \n",
    " \n",
    "  e.g.\n",
    "  \n",
    "  apple => ap\n",
    "  \n",
    "  banana => ba\n",
    "  \n",
    " \n",
    "### version two:\n",
    "####  (1) continue reading words from data until you have 4001 characters for training, and 1001 for testing\n",
    "####  (2) concatenate characters together to form structure features. \n",
    "####  (3) you will have the same amount structured data. \n",
    "  apple => ap, pp, pl, le\n",
    " \n",
    " banana => ba, an, na, an, na\n",
    "  \n",
    "### version three\n",
    "####  (1) similar to version two, but add a dummy letter '_' between words.\n",
    "  apple_banana => ap, pp, pl, le, e_, _b, ba, an, na, an, na\n",
    " \n",
    "### version four\n",
    "#### (1) similar, but window stride is 2 also, and pad a dummy letter '_', which will be represented as all 0 in the image. \n",
    "  apple => ap, pl, e_\n",
    "  \n",
    "  banana => ba, na,  na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Extract the first L letters in a word\n",
    "# You are welcome to try other options\n",
    "\n",
    "def structurize1(dataset, N, L):\n",
    "    d_features = len(dataset['features'][0])\n",
    "    y = dataset['labels']\n",
    "    X = dataset['features']\n",
    "    next_id = dataset['next_ids']\n",
    "\n",
    "    labels = np.zeros((N, L))\n",
    "    features = np.zeros((N, L*d_features))\n",
    "    \n",
    "    # Extract only one structured example\n",
    "    def extract(iN, loc):\n",
    "        labels[iN] = y[loc:loc+L]\n",
    "        features[iN] = np.array(X[loc:loc+L]).ravel().tolist()\n",
    "        iN += 1\n",
    "        return iN\n",
    "    \n",
    "    iN = 0\n",
    "    iN = extract(iN, 0)\n",
    "    \n",
    "    for key, value in enumerate(y):\n",
    "        if next_id[key] == -1:\n",
    "            iN = extract(iN, key+1)\n",
    "            \n",
    "            if iN == N:\n",
    "                break\n",
    "    \n",
    "    c = list(zip(labels, features))\n",
    "    random.shuffle(c)\n",
    "    labels, features = zip(*c)\n",
    "    print(np.array(labels))\n",
    "    \n",
    "    return np.array(labels), np.array(features)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels1, features1 = structurize1(dataset1, N, L)\n",
    "\n",
    "#print (np.all(labels1[labels1==labels1[0]]))\n",
    "#print (labels1[:15].T)\n",
    "#showFeatures(features1[:,0:128],15)\n",
    "#showFeatures(features1[:,128:256],15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use dlib to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N= 5000 L= [2, 3, 4, 5] d= 128\n"
     ]
    }
   ],
   "source": [
    "print ('N=',N,'L=',L_values,'d=',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeClassProblem:\n",
    "    C = 1\n",
    "\n",
    "    def __init__(self, samples, labels, L, K, d):\n",
    "        self.L = L\n",
    "        self.K = K\n",
    "        self.d = d\n",
    "        self.num_samples = len(samples)\n",
    "        self.num_dimensions = (L*K*d+1) + (L-1)\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        self.loss_for_loop = True\n",
    "        \n",
    "    def make_psi(self, x, label):\n",
    "       \n",
    "        psi = dlib.vector()\n",
    "        psi.resize(self.num_dimensions)\n",
    "        psi[0] = x[0] # The bias\n",
    "        \n",
    "        ########### YOUR CODE HERE ###########\n",
    "        # len(x) = 257\n",
    "        # num_features_per_label = 128\n",
    "        # len(psi) = 5890\n",
    "        \n",
    "        #start_1 = 1\n",
    "        #start_2 = 2945\n",
    "        #num_labels = 23\n",
    "                        \n",
    "        #index_1 = int(start_1 + (label[0] * self.d))\n",
    "        #index_2 = int(start_2 + (label[1] * self.d))\n",
    "    \n",
    "        \n",
    "        #for i in range(0, self.d - 1):\n",
    "        #    psi[index_1 + i] = float(x[1 + i])\n",
    "            \n",
    "        #for i in range(0, self.d - 1):\n",
    "        #    psi[index_2 + i] = float(x[129 + i])\n",
    "\n",
    "        #psi[self.num_dimensions - 1] = x[0] \n",
    "        \n",
    "        #return psi\n",
    "        \n",
    "        for i in range(self.L):\n",
    "            x_offset = 128 * i\n",
    "            x_offset += 1\n",
    "            psi_offset = label[i] * 128\n",
    "            psi_offset += i*self.K*self.d\n",
    "            psi_offset += 1\n",
    "            for j in range(d):\n",
    "                psi[psi_offset + j] =x[x_offset + j]\n",
    "        if(label[0] == label[1]):\n",
    "            psi[-1] = 0\n",
    "        else:\n",
    "            psi[-1] = 1\n",
    "        return psi\n",
    "\n",
    "    def get_truth_joint_feature_vector(self, idx):\n",
    "        return self.make_psi(self.samples[idx], self.labels[idx])\n",
    "    \n",
    "    def separation_oracle(self, idx, current_solution):\n",
    "        samp = self.samples[idx]\n",
    "        psi = [0]*self.num_dimensions\n",
    "        max1 = -1e10\n",
    "        max_scoring_label = [0]*L # Initialize max_scoring_label for icm search\n",
    "        for k in range(Niter):\n",
    "            for iL in range(self.L):   # Iterate over the window length\n",
    "                for i in range(self.K):# Change different label for the search of a structured label\n",
    "                    tmp_label = max_scoring_label.copy() ########### YOUR CODE HERE ########### # New a list to avoid modifying the max_scoring_label\n",
    "                    tmp_label[iL] = i ########### YOUR CODE HERE ########### # Take turns to modify the structured label from left to right. The guessed structured label.\n",
    "                    tmp_psi = self.make_psi(samp, tmp_label) ########### YOUR CODE HERE ########### # Make a new Psi for the guessed structured label\n",
    "                    score1 = dlib.dot(current_solution, tmp_psi)\n",
    "                    \n",
    "                    loss1 = 0.0\n",
    "                    if self.loss_for_loop:\n",
    "                        for j in range(self.L):\n",
    "                            if self.labels[idx][j] != tmp_label[j]:\n",
    "                                loss1 += 1.0\n",
    "                    else:\n",
    "                        if self.labels[idx] != tmp_label: # Add the conditional \"1\"\n",
    "                            loss1 += 1.0\n",
    "\n",
    "                    if max1 < score1+loss1: # Search for the maximum and update loss, max_scoring_label, and psi\n",
    "                        max1 = score1 + loss1\n",
    "                        loss = loss1\n",
    "                        max_scoring_label[iL] = i\n",
    "                        psi = tmp_psi\n",
    "\n",
    "        return loss, psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(samples, labels, problem, weights, K):\n",
    "    predictions = []\n",
    "    for samp in samples:\n",
    "        prediction = [0]*L # Initialize max_scoring_label for icm search\n",
    "        Niter = 2                 # The hyper-parameter for icm search\n",
    "        max1 = -1e10              # The max value during maximizing our target function\n",
    "        for k in range(Niter):\n",
    "            for iL in range(L):   # Iterate over the window length\n",
    "                for i in range(K):# Change differnet label for the search of a structured label\n",
    "                    tmp_label = prediction.copy() #labels[k][:] ########### YOUR CODE HERE ###########\n",
    "                    tmp_label[iL] = i ########### YOUR CODE HERE ###########\n",
    "                    psi1 = problem.make_psi(samp, tmp_label) ########### YOUR CODE HERE ###########\n",
    "                    score1 = dlib.dot(weights, psi1)\n",
    "\n",
    "                    if max1 < score1:\n",
    "                        max1 = score1\n",
    "                        prediction[iL] = i\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    \n",
    "    errCnt = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != labels[i]:\n",
    "            errCnt += 1\n",
    "\n",
    "    return 1.0-float(errCnt)/float(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le1 = preprocessing.LabelEncoder()\n",
    "#nplabels1  = le1.fit_transform(labels1.ravel()).reshape(labels1.shape)\n",
    "#npsamples1 = np.hstack([np.ones((N,1)), features1]) # Add ones for bias\n",
    "#1 = len(le1.classes_)\n",
    "#print ('K1=', K1)\n",
    "\n",
    "#tr_labels  = nplabels1[:int(N*0.8)].astype(int).tolist()\n",
    "#tr_samples = npsamples1[:int(N*0.8)].astype(int).tolist()\n",
    "#te_labels  = nplabels1[int(N*0.8):].astype(int).tolist()\n",
    "#te_samples = npsamples1[int(N*0.8):].astype(int).tolist()\n",
    "\n",
    "def profiling(labels):\n",
    "    TrDic = {}\n",
    "    for i in np.array(labels).ravel():\n",
    "        if i not in TrDic:\n",
    "            TrDic[i] = 1\n",
    "        else:\n",
    "            TrDic[i] += 1\n",
    "    return TrDic\n",
    "#print (profiling(tr_labels))\n",
    "#print (profiling(te_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem = ThreeClassProblem(tr_samples, tr_labels, L, K1, d)\n",
    "\n",
    "#start_train = timeit.default_timer()\n",
    "#weights = dlib.solve_structural_svm_problem(problem)\n",
    "#end_train = timeit.default_timer()\n",
    "#print (\"Training time elapsed:\", end_train - start_train, \"s\")\n",
    "#pickle.dump(weights, open('weights1_1.obj', 'wb'))\n",
    "##pickle.dump(weights, open('weights1_1.obj', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_load = pickle.load(open('weights1_1.obj','rb'))\n",
    "##weights_load = pickle.load(open('weights1_1.obj','r'))\n",
    "\n",
    "#print (\"Training accuracy=\", cal_accuracy(tr_samples, tr_labels, problem, weights_load, K1))\n",
    "#print (\"Test accuracy=\", cal_accuracy(te_samples, te_labels, problem, weights_load, K1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20. 12.]\n",
      " [14. 12.]\n",
      " [ 0. 19.]\n",
      " ...\n",
      " [ 4. 21.]\n",
      " [ 6. 14.]\n",
      " [ 4. 14.]]\n",
      "\n",
      "Labels and Features for L=2:\n",
      "True\n",
      "[[20. 14.  0. 15. 20.  4.  4. 14.  0.  0.  0.  0. 14. 20.  4.]\n",
      " [12. 12. 19. 14. 25.  0. 17. 12. 23. 13.  2. 19. 11.  6. 17.]]\n",
      "Profiling for L=2, train_size=1000, test_size=4000\n",
      "{17: 164, 11: 143, 13: 237, 0: 156, 16: 28, 14: 99, 22: 58, 4: 257, 15: 68, 20: 25, 12: 205, 2: 112, 10: 40, 6: 57, 7: 89, 3: 29, 8: 21, 21: 11, 18: 83, 19: 35, 1: 29, 9: 27, 5: 27}\n",
      "{13: 920, 11: 568, 12: 809, 2: 483, 17: 639, 4: 1034, 15: 296, 6: 221, 9: 120, 7: 379, 14: 297, 1: 117, 0: 669, 20: 122, 18: 286, 10: 221, 22: 210, 16: 118, 19: 105, 8: 55, 3: 117, 5: 108, 21: 106}\n",
      "Training time elapsed for L=2, train_size=1000, test_size=4000: 121.6878772340715 s\n",
      "Accuracy for L=2, train_size=1000, test_size=4000: 0.42274999999999996\n",
      "Testing time elapsed for L=2, train_size=1000, test_size=4000: 35.53041562344879 s\n",
      "Profiling for L=2, train_size=2500, test_size=2500\n",
      "{17: 396, 11: 355, 13: 577, 0: 412, 16: 69, 14: 217, 22: 139, 4: 656, 15: 171, 20: 79, 12: 495, 2: 302, 10: 121, 6: 124, 7: 235, 3: 67, 8: 48, 21: 59, 18: 185, 19: 80, 1: 71, 9: 81, 5: 61}\n",
      "{13: 580, 11: 356, 12: 519, 2: 293, 17: 407, 22: 129, 4: 635, 7: 233, 3: 79, 14: 179, 15: 193, 0: 413, 18: 184, 16: 77, 20: 68, 5: 74, 1: 75, 10: 140, 9: 66, 6: 154, 8: 28, 21: 58, 19: 60}\n",
      "Training time elapsed for L=2, train_size=2500, test_size=2500: 261.9229390555993 s\n",
      "Accuracy for L=2, train_size=2500, test_size=2500: 0.46399999999999997\n",
      "Testing time elapsed for L=2, train_size=2500, test_size=2500: 22.21438571996987 s\n",
      "Profiling for L=2, train_size=4000, test_size=1000\n",
      "{17: 644, 11: 564, 13: 930, 0: 670, 16: 114, 14: 322, 22: 220, 4: 1031, 15: 288, 20: 120, 12: 790, 2: 478, 10: 209, 6: 220, 7: 380, 3: 119, 8: 67, 21: 93, 18: 289, 19: 109, 1: 117, 9: 119, 5: 107}\n",
      "{15: 76, 0: 155, 12: 224, 19: 31, 4: 260, 18: 80, 2: 117, 13: 227, 11: 147, 16: 32, 17: 159, 22: 48, 6: 58, 7: 88, 1: 29, 14: 74, 20: 27, 21: 24, 10: 52, 9: 28, 3: 27, 8: 9, 5: 28}\n",
      "Training time elapsed for L=2, train_size=4000, test_size=1000: 422.80844332743436 s\n",
      "Accuracy for L=2, train_size=4000, test_size=1000: 0.482\n",
      "Testing time elapsed for L=2, train_size=4000, test_size=1000: 9.00538888387382 s\n",
      "[[ 0. 13. 16.]\n",
      " [ 0. 23.  8.]\n",
      " [17. 14.  9.]\n",
      " ...\n",
      " [13.  2. 14.]\n",
      " [13.  4. 23.]\n",
      " [ 4.  9. 20.]]\n",
      "\n",
      "Labels and Features for L=3:\n",
      "False\n",
      "[[ 0.  0. 17.  4.  4.  4. 10. 15.  4.  0.  4. 24.  4.  4. 17.]\n",
      " [13. 23. 14.  4.  0. 13.  8. 14. 14. 13. 13. 11. 21. 17. 14.]\n",
      " [16.  8.  9. 10. 17. 20.  8.  8.  6. 16. 20. 14. 21. 14.  9.]]\n",
      "Profiling for L=3, train_size=1000, test_size=4000\n",
      "{0: 156, 12: 234, 15: 31, 21: 53, 7: 193, 16: 151, 13: 429, 8: 41, 4: 321, 9: 88, 18: 203, 14: 164, 6: 105, 22: 24, 10: 54, 19: 105, 5: 52, 11: 161, 17: 37, 2: 156, 3: 74, 23: 118, 20: 23, 1: 27}\n",
      "{16: 600, 13: 1597, 8: 148, 9: 332, 7: 717, 4: 1246, 18: 945, 22: 93, 10: 207, 12: 1024, 20: 117, 2: 583, 14: 610, 11: 680, 6: 450, 19: 395, 21: 221, 5: 218, 23: 522, 0: 669, 17: 180, 3: 218, 1: 119, 15: 109}\n",
      "Training time elapsed for L=3, train_size=1000, test_size=4000: 356.56413018517196 s\n",
      "Accuracy for L=3, train_size=1000, test_size=4000: 0.254\n",
      "Testing time elapsed for L=3, train_size=1000, test_size=4000: 83.25675500649959 s\n",
      "Profiling for L=3, train_size=2500, test_size=2500\n",
      "{0: 397, 12: 627, 15: 74, 21: 122, 7: 443, 16: 377, 13: 1041, 8: 97, 4: 793, 9: 204, 18: 575, 14: 394, 6: 284, 22: 68, 10: 150, 19: 249, 5: 136, 11: 379, 17: 101, 2: 385, 3: 148, 23: 321, 20: 66, 1: 69}\n",
      "{4: 774, 13: 985, 6: 271, 12: 631, 18: 573, 11: 462, 14: 380, 16: 374, 8: 92, 2: 354, 0: 428, 23: 319, 9: 216, 10: 111, 7: 467, 3: 144, 19: 251, 1: 77, 17: 116, 21: 152, 22: 49, 15: 66, 20: 74, 5: 134}\n",
      "Training time elapsed for L=3, train_size=2500, test_size=2500: 683.7380159217864 s\n",
      "Accuracy for L=3, train_size=2500, test_size=2500: 0.2812\n",
      "Testing time elapsed for L=3, train_size=2500, test_size=2500: 52.00858266931027 s\n",
      "Profiling for L=3, train_size=4000, test_size=1000\n",
      "{0: 643, 12: 1001, 15: 109, 21: 207, 7: 740, 16: 602, 13: 1641, 8: 161, 4: 1229, 9: 329, 18: 936, 14: 615, 6: 444, 22: 97, 10: 218, 19: 380, 5: 212, 11: 668, 17: 179, 2: 598, 3: 236, 23: 534, 20: 110, 1: 111}\n",
      "{13: 385, 10: 43, 2: 141, 6: 111, 12: 257, 4: 338, 21: 67, 0: 182, 16: 149, 18: 212, 23: 106, 11: 173, 14: 159, 20: 30, 7: 170, 3: 56, 5: 58, 19: 120, 9: 91, 1: 35, 17: 38, 8: 28, 15: 31, 22: 20}\n",
      "Training time elapsed for L=3, train_size=4000, test_size=1000: 1208.4985075909644 s\n",
      "Accuracy for L=3, train_size=4000, test_size=1000: 0.28900000000000003\n",
      "Testing time elapsed for L=3, train_size=4000, test_size=1000: 21.039940176531672 s\n",
      "[[14. 21.  4. 17.]\n",
      " [ 0. 19.  4.  0.]\n",
      " [ 8.  3.  3.  8.]\n",
      " ...\n",
      " [14. 21.  4. 17.]\n",
      " [20.  8. 25. 25.]\n",
      " [20. 12. 15. 20.]]\n",
      "\n",
      "Labels and Features for L=4:\n",
      "True\n",
      "[[14.  0.  8.  2. 20.  4.  4. 14.  4. 12.  4. 13. 20.  4. 14.]\n",
      " [21. 19.  3.  2.  5. 13.  9. 12. 21.  1. 14. 13. 25. 17. 12.]\n",
      " [ 4.  4.  3. 14.  5. 20. 20. 15. 21. 17.  6. 14. 25. 14. 15.]\n",
      " [17.  0.  8. 20. 20.  4. 21.  0.  8.  0. 17. 20. 11.  4. 11.]]\n",
      "Profiling for L=4, train_size=1000, test_size=4000\n",
      "{13: 405, 20: 109, 4: 452, 16: 242, 0: 317, 18: 64, 7: 339, 3: 72, 2: 124, 19: 382, 5: 50, 12: 292, 8: 34, 11: 201, 14: 200, 1: 60, 6: 103, 24: 156, 10: 147, 9: 98, 15: 29, 23: 18, 21: 27, 22: 55, 17: 24}\n",
      "{19: 1580, 24: 588, 10: 644, 4: 1651, 8: 155, 20: 467, 0: 1293, 18: 224, 16: 912, 13: 1745, 6: 452, 7: 1262, 11: 869, 1: 217, 2: 615, 9: 323, 12: 1114, 14: 820, 5: 220, 3: 220, 22: 219, 15: 111, 17: 87, 23: 99, 21: 113}\n",
      "Training time elapsed for L=4, train_size=1000, test_size=4000: 703.7253822106868 s\n",
      "Accuracy for L=4, train_size=1000, test_size=4000: 0.19325000000000003\n",
      "Testing time elapsed for L=4, train_size=1000, test_size=4000: 148.79399129282683 s\n",
      "Profiling for L=4, train_size=2500, test_size=2500\n",
      "{13: 1051, 20: 279, 4: 1078, 16: 599, 0: 810, 18: 145, 7: 833, 3: 148, 2: 358, 19: 954, 5: 130, 12: 702, 8: 96, 11: 521, 14: 485, 1: 153, 6: 282, 24: 380, 10: 380, 9: 238, 15: 69, 23: 51, 21: 69, 22: 136, 17: 53}\n",
      "{0: 800, 12: 704, 15: 71, 19: 1008, 7: 768, 3: 144, 11: 549, 14: 535, 2: 381, 9: 183, 4: 1025, 13: 1099, 6: 273, 16: 555, 1: 124, 23: 66, 10: 411, 22: 138, 24: 364, 21: 71, 20: 297, 18: 143, 5: 140, 17: 58, 8: 93}\n",
      "Training time elapsed for L=4, train_size=2500, test_size=2500: 1467.7372232452035 s\n",
      "Accuracy for L=4, train_size=2500, test_size=2500: 0.21919999999999995\n",
      "Testing time elapsed for L=4, train_size=2500, test_size=2500: 93.48128993157297 s\n",
      "Profiling for L=4, train_size=4000, test_size=1000\n",
      "{13: 1719, 20: 442, 4: 1680, 16: 922, 0: 1302, 18: 231, 7: 1269, 3: 226, 2: 591, 19: 1573, 5: 204, 12: 1121, 8: 155, 11: 871, 14: 813, 1: 222, 6: 439, 24: 630, 10: 637, 9: 337, 15: 109, 23: 85, 21: 111, 22: 224, 17: 87}\n",
      "{16: 232, 13: 431, 8: 34, 4: 423, 0: 308, 18: 57, 2: 148, 19: 389, 12: 285, 17: 24, 14: 207, 7: 332, 10: 154, 9: 84, 11: 199, 1: 55, 15: 31, 20: 134, 6: 116, 22: 50, 23: 32, 24: 114, 21: 29, 5: 66, 3: 66}\n",
      "Training time elapsed for L=4, train_size=4000, test_size=1000: 2517.0639919433743 s\n",
      "Accuracy for L=4, train_size=4000, test_size=1000: 0.22299999999999998\n",
      "Testing time elapsed for L=4, train_size=4000, test_size=1000: 37.10649454779923 s\n",
      "[[ 0. 19.  4.  0. 19.]\n",
      " [20. 25. 25. 20. 25.]\n",
      " [ 4.  0. 17.  1. 14.]\n",
      " ...\n",
      " [ 4.  0. 17.  1. 14.]\n",
      " [12.  8. 19. 19.  4.]\n",
      " [10.  8.  8. 13.  6.]]\n",
      "\n",
      "Labels and Features for L=5:\n",
      "False\n",
      "[[ 0. 20.  4. 20.  4.  2. 17. 13. 20.  0.  0.  0. 20.  4. 24.]\n",
      " [19. 25.  0.  8.  0.  2.  0.  4. 25.  2.  2. 23. 25.  2. 11.]\n",
      " [ 4. 25. 17. 25. 17. 14. 13. 23. 25. 10. 10.  8. 25. 14. 14.]\n",
      " [ 0. 20.  1. 25.  1. 20. 18. 15. 20.  8.  8.  0. 11. 12. 15.]\n",
      " [19. 25. 14.  8. 14. 13.  5.  4. 25. 13. 13. 23.  4. 15.  7.]]\n",
      "Profiling for L=5, train_size=1000, test_size=4000\n",
      "{0: 366, 19: 92, 4: 537, 20: 395, 25: 200, 17: 326, 1: 63, 14: 476, 8: 390, 2: 203, 13: 580, 18: 17, 5: 100, 23: 78, 15: 234, 10: 111, 11: 152, 12: 232, 24: 19, 7: 19, 6: 130, 3: 50, 16: 32, 9: 43, 21: 122, 22: 33}\n",
      "{14: 1820, 21: 454, 4: 2100, 17: 1193, 13: 2285, 24: 98, 11: 639, 15: 920, 7: 98, 8: 1604, 12: 988, 1: 214, 0: 1501, 2: 781, 10: 450, 20: 1567, 25: 823, 6: 573, 23: 342, 5: 511, 3: 242, 9: 146, 16: 108, 22: 108, 19: 341, 18: 94}\n",
      "Training time elapsed for L=5, train_size=1000, test_size=4000: 1305.587338901125 s\n",
      "Accuracy for L=5, train_size=1000, test_size=4000: 0.09099999999999997\n",
      "Testing time elapsed for L=5, train_size=1000, test_size=4000: 242.53680658247322 s\n",
      "Profiling for L=5, train_size=2500, test_size=2500\n",
      "{0: 932, 19: 226, 4: 1323, 20: 1004, 25: 516, 17: 734, 1: 140, 14: 1126, 8: 986, 2: 479, 13: 1453, 18: 54, 5: 302, 23: 233, 15: 595, 10: 280, 11: 400, 12: 592, 24: 53, 7: 53, 6: 335, 3: 150, 16: 61, 9: 96, 21: 299, 22: 78}\n",
      "{4: 1314, 0: 935, 17: 785, 1: 137, 14: 1170, 9: 93, 2: 505, 24: 64, 11: 391, 15: 559, 7: 64, 12: 628, 21: 277, 13: 1412, 20: 958, 6: 368, 25: 507, 23: 187, 8: 1008, 5: 309, 19: 207, 18: 57, 10: 281, 22: 63, 3: 142, 16: 79}\n",
      "Training time elapsed for L=5, train_size=2500, test_size=2500: 2666.5413136146963 s\n",
      "Accuracy for L=5, train_size=2500, test_size=2500: 0.12239999999999995\n",
      "Testing time elapsed for L=5, train_size=2500, test_size=2500: 152.27888596989214 s\n",
      "Profiling for L=5, train_size=4000, test_size=1000\n",
      "{0: 1539, 19: 356, 4: 2115, 20: 1533, 25: 792, 17: 1211, 1: 233, 14: 1819, 8: 1599, 2: 807, 13: 2290, 18: 93, 5: 464, 23: 353, 15: 915, 10: 445, 11: 642, 12: 987, 24: 91, 7: 91, 6: 550, 3: 248, 16: 103, 9: 153, 21: 463, 22: 108}\n",
      "{13: 575, 22: 33, 14: 477, 17: 308, 10: 116, 4: 522, 12: 233, 15: 239, 11: 149, 0: 328, 20: 429, 16: 37, 8: 395, 5: 147, 19: 77, 6: 153, 2: 177, 25: 231, 9: 36, 1: 44, 21: 113, 23: 67, 24: 26, 7: 26, 3: 44, 18: 18}\n"
     ]
    }
   ],
   "source": [
    "for L in L_values:\n",
    "    labels1, features1 = structurize1(dataset1, N, L)\n",
    "    \n",
    "    print(f\"\\nLabels and Features for L={L}:\")\n",
    "    print(np.all(labels1[labels1 == labels1[0]]))\n",
    "    print(labels1[:15].T)\n",
    "    showFeatures(features1[:, 0:128], 15)\n",
    "    showFeatures(features1[:, 128:256], 15)\n",
    "    \n",
    "    le1 = preprocessing.LabelEncoder()\n",
    "    nplabels1 = le1.fit_transform(labels1.ravel()).reshape(labels1.shape)\n",
    "    npsamples1 = np.hstack([np.ones((N, 1)), features1])  # Add ones for bias\n",
    "    K1 = len(le1.classes_)\n",
    "\n",
    "    for train_size, test_size in splits:\n",
    "        tr_labels = nplabels1[:train_size].astype(int).tolist()\n",
    "        tr_samples = npsamples1[:train_size].astype(int).tolist()\n",
    "        te_labels = nplabels1[train_size:train_size + test_size].astype(int).tolist()\n",
    "        te_samples = npsamples1[train_size:train_size + test_size].astype(int).tolist()\n",
    "\n",
    "        print(f\"Profiling for L={L}, train_size={train_size}, test_size={test_size}\")\n",
    "        print(profiling(tr_labels))\n",
    "        print(profiling(te_labels))\n",
    "\n",
    "        problem = ThreeClassProblem(tr_samples, tr_labels, L, K1, d)\n",
    "\n",
    "        start_train = timeit.default_timer()\n",
    "        weights = dlib.solve_structural_svm_problem(problem)\n",
    "        end_train = timeit.default_timer()\n",
    "        print(f\"Training time elapsed for L={L}, train_size={train_size}, test_size={test_size}:\",\n",
    "              end_train - start_train, \"s\")\n",
    "\n",
    "        pickle.dump(weights, open(f'weights_L_{L}_train_{train_size}_test_{test_size}.p', 'wb'))\n",
    "\n",
    "        start_test = timeit.default_timer()\n",
    "        print(f\"Accuracy for L={L}, train_size={train_size}, test_size={test_size}:\",\n",
    "              cal_accuracy(te_samples, te_labels, problem, weights, K1))\n",
    "        end_test = timeit.default_timer()\n",
    "        print(f\"Testing time elapsed for L={L}, train_size={train_size}, test_size={test_size}:\",\n",
    "              end_test - start_test, \"s\")\n",
    "\n",
    "        with open(f'performance_L_{L}_train_{train_size}_test_{test_size}.txt', 'w') as f:\n",
    "            f.write(f\"Training time: {end_train - start_train} s\\n\")\n",
    "            f.write(f\"Testing time: {end_test - start_test} s\\n\")\n",
    "            f.write(f\"Accuracy: {cal_accuracy(te_samples, te_labels, problem, weights, K1)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
